{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2η άσκηση\n",
    "\n",
    "#Ο κώδικας δοκιμάστηκε και τα αποτελέσματα έχουν αποθηκευτεί. Γενικά, η εκτέλεσή του είναι χρονοβόρα. \n",
    "#Σημειώνεται πως για να έχουμε μεγάλα ποσοστά ακρίβειας απαιτείται εκπαίδευση για περισσότερες εποχές.\n",
    "#Έτσι, οι περίοδοι εκαπάιδευσης είναι ενδεικτικές και επιλέχθηκαν για τον περιορισμό, σε λογικά πλαίσια, του χρόνου εκτέλεσης του κώδικα.   \n",
    "from __future__ import absolute_import, division, print_function, unicode_literals # legacy compatibility\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# helper functions\n",
    "\n",
    "#Συνάρτηση για τη δημιουργία μοντέλου Softmax\n",
    "def create_sft():\n",
    "  softmax = Sequential([\n",
    "      Flatten(input_shape=(32, 32 ,3)),\n",
    "      Dense(200, activation='softmax')\n",
    "  ])\n",
    "  return softmax\n",
    "\n",
    "#Συνάρτηση για τη δημιουργία μοντέλου MLP\n",
    "def create_mlp():\n",
    "  mlp = Sequential([\n",
    "    Flatten(input_shape=(32, 32 ,3)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(200, activation='softmax')\n",
    "  ])\n",
    "  return mlp\n",
    "\n",
    "#Συνάρτηση για τη δημιουργία μοντέλου LeNet\n",
    "def create_lenet():\n",
    "  lenet = models.Sequential()\n",
    "  lenet.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) \n",
    "  lenet.add(layers.MaxPooling2D((2, 2)))\n",
    "  lenet.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "  lenet.add(layers.MaxPooling2D((2, 2)))\n",
    "  lenet.add(layers.Flatten())\n",
    "  lenet.add(layers.Dense(512, activation='relu'))\n",
    "  lenet.add(layers.Dense(200, activation='softmax'))\n",
    "  return lenet\n",
    "\n",
    "#Συνάρτηση για τη δημιουργία μοντέλου CNN1\n",
    "def create_cnn1():\n",
    "  cnn1 = models.Sequential()\n",
    "  cnn1.add(layers.Conv2D(16, (5, 5), activation='relu', input_shape=(32, 32, 3))) \n",
    "  cnn1.add(layers.MaxPooling2D((2, 2)))\n",
    "  cnn1.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "  cnn1.add(layers.MaxPooling2D((2, 2)))\n",
    "  cnn1.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "  cnn1.add(layers.Flatten())\n",
    "  cnn1.add(layers.Dense(200, activation='softmax'))\n",
    "  return cnn1\n",
    "\n",
    "#Συνάρτηση για τη δημιουργία μοντέλου CNN2\n",
    "def create_cnn2():\n",
    "  cnn2 = models.Sequential()\n",
    "  cnn2.add(layers.Conv2D(16, (5, 5), activation='relu', input_shape=(32, 32, 3))) \n",
    "  cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "  cnn2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "  cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "  cnn2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "  cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "  cnn2.add(layers.Flatten())\n",
    "  cnn2.add(layers.Dense(200, activation='softmax'))\n",
    "  return cnn2\n",
    "\n",
    "#Με την παρακάτω μέθοδο κάνουμε plot τα διαγράμματα της ακρίβειας εκπαίδευσης (accuracy) και της ακρίβειας επικύρωσης (val_accuracy) σε συνάρτηση με τον αριθμό των εποχών.\n",
    "def plot_acc(title,acc,val_acc):\n",
    "  fig1,ax1=plt.subplots()\n",
    "  ax1.plot(acc, label='accuracy')\n",
    "  ax1.plot(val_acc, label = 'val_accuracy')\n",
    "  ax1.set_title(title)\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.set_ylabel('Accuracy')\n",
    "  ax1.legend(loc='best')\n",
    "  plt.show()\n",
    "\n",
    "#Δοκιμάζουμε τα μοντέλα για δοθέν dataset και δεδομένο batch size.  \n",
    "#Η συνάρτηση επιστρέφει μία τούπλα δύο στοιχείων. Το 1ο, συνιστά μια λίστα με τις τιμές της ακρίβειας εκπαίδευσης που πετυχαίνει μοντέλο για τους διαφορετικούς optimizers.\n",
    "#Το 2ο, κατ'αναλογία, περιέχει τιμές της ακρίβειας επικύρωσης.\n",
    "def check_classes(x_train,y_train,x_test,y_test,batch_size):\n",
    "  model_acc=[]\n",
    "  model_val_acc=[]\n",
    "  model=create_sft()\n",
    "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:Softmax,\",\"Optimizer:adam\") \n",
    "  model_adam=model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adam.history['val_accuracy'][-1])\n",
    "  model=create_mlp()\n",
    "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:MLP,\",\"Optimizer:adam\") \n",
    "  model_adam=model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adam.history['val_accuracy'][-1])\n",
    "  model=create_lenet()\n",
    "  model.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:LeNet,\",\"Optimizer:nadam\") \n",
    "  model_nadam=model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_nadam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_nadam.history['val_accuracy'][-1])\n",
    "  model=create_cnn1()\n",
    "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:CNN1,\",\"Optimizer:adam\") \n",
    "  model_adam=model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adam.history['val_accuracy'][-1])\n",
    "  model=create_cnn2()\n",
    "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:CNN2,\",\"Optimizer:adam\") \n",
    "  model_adam=model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_data=(x_test, y_test))\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adam.history['val_accuracy'][-1])\n",
    "  return (model_acc,model_val_acc) \n",
    "\n",
    "#Δοκιμάζουμε όλους τους optimizers για ένα μοντέλο. Ο τύπος του τελευταίου καθορίζεται από το string model_name.\n",
    "#Η συνάρτηση επιστρέφει μία τούπλα δύο στοιχείων. Το 1ο, συνιστά μια λίστα με τις τιμές της ακρίβειας εκπαίδευσης που πετυχαίνει μοντέλο για τους διαφορετικούς optimizers.\n",
    "#Το 2ο, κατ'αναλογία, περιέχει τιμές της ακρίβειας επικύρωσης.\n",
    "def check_opt(model_name,x_train,y_train,x_test,y_test):\n",
    "  model_acc=[]\n",
    "  model_val_acc=[]\n",
    "  model = choose(model_name) \n",
    "  model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:sgd\") \n",
    "  model_sgd=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_sgd.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_sgd.history['val_accuracy'][-1])\n",
    "  model=choose(model_name)\n",
    "  model.compile(optimizer='RMSprop',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:RMSprop\") \n",
    "  model_rms=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_rms.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_rms.history['val_accuracy'][-1])\n",
    "  model=choose(model_name)\n",
    "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:adam\") \n",
    "  model_adam=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adam.history['val_accuracy'][-1])\n",
    "  model=choose(model_name)\n",
    "  model.compile(optimizer='adadelta',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:adadelta\") \n",
    "  model_adadelta=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adadelta.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adadelta.history['val_accuracy'][-1])\n",
    "  model = choose(model_name) \n",
    "  model.compile(optimizer='adagrad',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:adagrad\") \n",
    "  model_adagrad=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adagrad.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adagrad.history['val_accuracy'][-1])\n",
    "  model = choose(model_name) \n",
    "  model.compile(optimizer='adamax',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:adamax\") \n",
    "  model_adamax=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_adamax.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_adamax.history['val_accuracy'][-1])\n",
    "  model=choose(model_name) \n",
    "  model.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:nadam\") \n",
    "  model_nadam=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_nadam.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_nadam.history['val_accuracy'][-1])\n",
    "  model=choose(model_name) \n",
    "  model.compile(optimizer='Ftrl',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "  print(\"Model:%s,\" %(model_name),\"Optimizer:Ftrl\") \n",
    "  model_ftrl=model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test)) \n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(test_acc,'\\n')\n",
    "  model_acc.append(model_ftrl.history['accuracy'][-1])\n",
    "  model_val_acc.append(model_ftrl.history['val_accuracy'][-1])\n",
    "  return (model_acc,model_val_acc) \n",
    "\n",
    "#Κατασκευή του ζητούμενου μοντέλου, όπως αυτό καθορίζεται από την παράμετρο model_name.\n",
    "def choose(model_name):\n",
    "  if (model_name=='Softmax'):\n",
    "    model=create_sft()\n",
    "  elif (model_name=='MLP'):\n",
    "    model=create_mlp()\n",
    "  elif (model_name=='LeNet'):\n",
    "    model=create_lenet()\n",
    "  elif (model_name=='CNN1'):\n",
    "    model=create_cnn1()\n",
    "  else:\n",
    "    model=create_cnn2()\n",
    "  return model\n",
    "\n",
    "#Σχεδιασμός γραφικών παραστάσεων στο ίδιο διάγραμμα.\n",
    "def plot_all(title,sft,mlp,lenet,cnn1,cnn2,x,flag):\n",
    "  fig1,ax1=plt.subplots()\n",
    "  x_ticks=np.arange(0,len(x))\n",
    "  x_labels=map(str,x)\n",
    "  ax1.xaxis.set_ticks(x_ticks)\n",
    "  ax1.xaxis.set_ticklabels(x_labels)\n",
    "  ax1.plot(x_ticks, sft, label='Softmax')\n",
    "  ax1.plot(x_ticks, mlp,  label= 'MLP')\n",
    "  ax1.plot(x_ticks, lenet, label='LeNet')\n",
    "  ax1.plot(x_ticks, cnn1, label= 'CNN1')\n",
    "  ax1.plot(x_ticks, cnn2, label='CNN2')\n",
    "  ax1.set_title(title)\n",
    "  if (flag==0):\n",
    "    ax1.set_xlabel('Number of Classes')\n",
    "  else:\n",
    "    ax1.set_xlabel('Batch Size')\n",
    "  ax1.set_ylabel('Accuracy')\n",
    "  ax1.legend(loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "#Απεικόνιση, σε ραβδόγραμμα, των μετρικών acc και val_acc για συγκεκριμένο μοντέλο.\n",
    "def plot_pairs(title,acc,val_acc,x):\n",
    "  fig,ax=plt.subplots()\n",
    "  index=np.arange(len(x))\n",
    "  bar_width=0.3\n",
    "  rects1=plt.bar(index,acc,bar_width,color='b',label='accuracy')\n",
    "  rects2=plt.bar(index+bar_width,val_acc,bar_width,color='tab:orange',label='val_accuracy')\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Optimizers')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xticks(index+bar_width,x)\n",
    "  plt.legend(loc='upper center')\n",
    "  plt.show()\n",
    "\n",
    "# Κώδικας από το notebook της άσκησης.\n",
    "# select from from_list elements with index in index_list\n",
    "def select_from_list(from_list, index_list):\n",
    "  filtered_list= [from_list[i] for i in index_list]\n",
    "  return(filtered_list)\n",
    "\n",
    "# append in filtered_list the index of each element of unfilterd_list if it exists in in target_list\n",
    "def get_ds_index(unfiliterd_list, target_list):\n",
    "  index = 0\n",
    "  filtered_list=[]\n",
    "  for i_ in unfiliterd_list:\n",
    "    if i_[0] in target_list:\n",
    "      filtered_list.append(index)\n",
    "    index += 1\n",
    "  return(filtered_list)\n",
    "\n",
    "# select a url for a unique subset of CIFAR-100 with 20, 40, 60, or 80 classes\n",
    "def select_classes_number(classes_number = 20):\n",
    "  cifar100_20_classes_url = \"https://pastebin.com/raw/nzE1n98V\"\n",
    "  cifar100_40_classes_url = \"https://pastebin.com/raw/zGX4mCNP\"\n",
    "  cifar100_60_classes_url = \"https://pastebin.com/raw/nsDTd3Qn\"\n",
    "  cifar100_80_classes_url = \"https://pastebin.com/raw/SNbXz700\"\n",
    "  if classes_number == 20:\n",
    "    return cifar100_20_classes_url\n",
    "  elif classes_number == 40:\n",
    "    return cifar100_40_classes_url\n",
    "  elif classes_number == 60:\n",
    "    return cifar100_60_classes_url\n",
    "  elif classes_number == 80:\n",
    "    return cifar100_80_classes_url\n",
    "  else:\n",
    "    return -1\n",
    "\n",
    "#Επιλογή και φόρτωση δεδομένων από το CIFAR100. \n",
    "def feed_data(class_num):\n",
    "  (x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "  team_seed = 26\n",
    "  cifar100_classes_url = select_classes_number(class_num)\n",
    "  team_classes = pd.read_csv(cifar100_classes_url, sep=',', header=None)\n",
    "  CIFAR100_LABELS_LIST = pd.read_csv('https://pastebin.com/raw/qgDaNggt', sep=',', header=None).astype(str).values.tolist()[0]\n",
    "\n",
    "  our_index = team_classes.iloc[team_seed,:].values.tolist()\n",
    "  our_classes = select_from_list(CIFAR100_LABELS_LIST, our_index)\n",
    "  train_index = get_ds_index(y_train_all, our_index)\n",
    "  test_index = get_ds_index(y_test_all, our_index)\n",
    "\n",
    "  x_train_ds = np.asarray(select_from_list(x_train_all, train_index))\n",
    "  y_train_ds = np.asarray(select_from_list(y_train_all, train_index))\n",
    "  x_test_ds = np.asarray(select_from_list(x_test_all, test_index))\n",
    "  y_test_ds = np.asarray(select_from_list(y_test_all, test_index))\n",
    "\n",
    "  # get (train) dataset dimensions\n",
    "  data_size, img_rows, img_cols, img_channels = x_train_ds.shape\n",
    "\n",
    "  # set validation set percentage (wrt the training set size)\n",
    "  validation_percentage = 0.15\n",
    "  val_size = round(validation_percentage * data_size)\n",
    "\n",
    "  # Reserve val_size samples for validation and normalize all values\n",
    "  x_val = x_train_ds[-val_size:]/255\n",
    "  y_val = y_train_ds[-val_size:]\n",
    "  x_train = x_train_ds[:-val_size]/255\n",
    "  y_train = y_train_ds[:-val_size]\n",
    "  x_test = x_test_ds/255\n",
    "  y_test = y_test_ds\n",
    "  return (x_train,y_train,x_test,y_test)\n",
    "\n",
    "# get class label from class index\n",
    "def class_label_from_index(fine_category):\n",
    "  return(CIFAR100_LABELS_LIST[fine_category.item(0)])\n",
    "\n",
    "#Επιλογή δεδομένων για 20 κλάσεις.\n",
    "total=feed_data(20)\n",
    "x_train=total[0]\n",
    "y_train=total[1]\n",
    "x_test=total[2]\n",
    "y_test=total[3]\n",
    "\n",
    "#1.1.1\n",
    "##Χρησιμοποιούμε τις μεθόδους που ορίστηκαν πιο πάνω, ώστε να μπορούμε να κάνουμε δοκιμές με διαφορετικές παραμετροποιήσεις.\n",
    "#Softmax\n",
    "softmax = create_sft()\n",
    "print('Softmax summary:')\n",
    "softmax.summary()\n",
    "#MLP\n",
    "mlp = create_mlp()\n",
    "print('\\n')\n",
    "print('MLP summary:')\n",
    "mlp.summary()\n",
    "#LeNet\n",
    "lenet = create_lenet()\n",
    "print('\\n')\n",
    "print('LeNet summary:')\n",
    "lenet.summary()\n",
    "#CNN1\n",
    "cnn1 = create_cnn1()\n",
    "print('\\n')\n",
    "print('CNN1 summary:')\n",
    "cnn1.summary()\n",
    "#CNN2\n",
    "cnn2 = create_cnn2()\n",
    "print('\\n')\n",
    "print('CNN2 summary:')\n",
    "cnn2.summary()\n",
    "#1.1.2: Δοκιμάζουμε διαφορετικές τιμές για κάθε παράμετρο. Για τον optimizer επιλέγουμε μεταξύ των:sgd,RMSprop,adam,adadelta,adagrad,adamax,nadam,ftrl. \n",
    "####### Αντίστοιχα, για τη συνάρτηση απωλειών έχουμε τις περιπτώσεις: sparse_categorical_crossentropy,poisson,kullback_leibler_divergence. Τέλος, ως μετρική χρησιμοποιούμε την accuracy. \n",
    "####### Σημειώνεται πως οι συναρτήσεις BinaryCrossentropy και CategoricalCrossentropy δεν βρίσκουν εφαρμογή στο dataset μας, καθώς έχουμε πολλές κατηγορίες (παραπάνω από 2) τύπου int. \n",
    "####### Ως αποτέλεσμα, οι ανάλογες μετρικές δεν μπορούν να χρησιμοποιηθούν.\n",
    "####### Τέλος, επιλέγουμε την μετρική accuracy, επειδή εκφράζει το συνολικό ποσοστό των πετυχημένων προβλέψεών μας. Η συμπεριφορά αυτή θεωρήθηκε προτιμότερη από, λόγου χάρη, αυτή της sparse_top_k_categorical_accuracy,που\n",
    "####### μας δείχνει αν η εκτίμησή μας είναι εντός των k πιο πιθανών. Επιλέγουμε παραμετροποιήσεις που δίνουν τη μεγαλύτερη ακρίβεια εκπαίδευσης με το πέρας των εποχών.     \n",
    "####### Ο κώδικας που εκτελέσαμε για να ελέγξουμε την ακρίβεια των μοντέλων παρουσιάζεται παρακάτω. Δίνεται ως σχόλιο, αφού η εκτέλεση του απαιτεί χρόνο.\n",
    "####### Η συνάρτηση create_model μπορεί να είναι μία από τις create_sft(),create_mlp(),create_lenet(),create_cnn1() και create_cnn2(), ανάλογα με το υπό εξέταση μοντέλο.\n",
    "\n",
    "'''\n",
    "opt=['sgd','RMSprop','adam','adadelta','adagrad','adamax','nadam','ftrl']\n",
    "losses=['sparse_categorical_crossentropy','poisson','kullback_leibler_divergence']\n",
    "met=['accuracy']\n",
    "\n",
    "for o in opt:\n",
    "  for l in losses:\n",
    "    for m in met:\n",
    "      print(o,l,m)\n",
    "      model=create_model()\n",
    "      model.compile(optimizer=o,loss=l,metrics=m)\n",
    "      model.fit(x_train, y_train, epochs=5)\n",
    "'''\n",
    "#Παρατηρούμε πως οι επιμέρους αρχιτεκτονικές διαφέρουν μόνο ως προς τον optimizer.\n",
    "print('\\n')\n",
    "print('Ερώτημα 1\\n')\n",
    "print('Βήμα 1.2\\n')\n",
    "print(\"Model:Softmax, Optimizer:adam\") \n",
    "softmax.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy') #επιλεγμένη αρχιτεκτονική για Softmax\n",
    "sft_adam=softmax.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = softmax.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "softmax = create_sft() #Νέο μοντέλο για την 2η δοκιμή.\n",
    "print(\"Model:Softmax, Optimizer:adamax\") \n",
    "softmax.compile(optimizer='adamax',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "sft_adamax=softmax.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = softmax.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "\n",
    "print(\"Model:MLP, Optimizer:nadam\") \n",
    "mlp.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "mlp_nadam=mlp.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = mlp.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "mlp = create_mlp() #Νέο μοντέλο για την 2η δοκιμή.\n",
    "print(\"Model:MLP, Optimizer:adam\") \n",
    "mlp.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "mlp_adam=mlp.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test)) #επιλεγμένη αρχιτεκτονική για MLP\n",
    "test_loss, test_acc = mlp.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "\n",
    "print(\"Model:LeNet, Optimizer:nadam\") \n",
    "lenet.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "lenet_nadam=lenet.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test)) #επιλεγμένη αρχιτεκτονική για LeNet\n",
    "test_loss, test_acc = lenet.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "lenet = create_lenet() #Νέο μοντέλο για την 2η δοκιμή.\n",
    "print(\"Model:LeNet, Optimizer:RMSprop\") \n",
    "lenet.compile(optimizer='RMSprop',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "lenet_rms=lenet.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = lenet.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "\n",
    "print(\"Model:CNN1, Optimizer:nadam\") \n",
    "cnn1.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "cnn1_nadam=cnn1.fit(x_train, y_train, epochs=15,validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = cnn1.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "cnn1 = create_cnn1() #Νέο μοντέλο για την 2η δοκιμή.\n",
    "print(\"Model:CNN1, Optimizer:adam\") \n",
    "cnn1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "cnn1_adam=cnn1.fit(x_train, y_train, epochs=15,validation_data=(x_test, y_test)) #επιλεγμένη αρχιτεκτονική για CNN1\n",
    "test_loss, test_acc = cnn1.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "\n",
    "print(\"Model:CNN2, Optimizer:nadam\") \n",
    "cnn2.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "cnn2_nadam=cnn2.fit(x_train, y_train, epochs=15,validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = cnn2.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "cnn2 = create_cnn2() #Νέο μοντέλο για την 2η δοκιμή.\n",
    "print(\"Model:CNN2, Optimizer:adam\") \n",
    "cnn2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "cnn2_adam=cnn2.fit(x_train, y_train, epochs=15,validation_data=(x_test, y_test)) #επιλεγμένη αρχιτεκτονική για CNN2\n",
    "test_loss, test_acc = cnn2.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "\n",
    "#1.2.1\n",
    "#Διαγράμματα για το μοντέλο Softmax\n",
    "print('Βήμα 2.1\\n')\n",
    "plot_acc('Softmax(adam)',sft_adam.history['accuracy'],sft_adam.history['val_accuracy'])\n",
    "plot_acc('Softmax(adamax)',sft_adamax.history['accuracy'],sft_adamax.history['val_accuracy'])\n",
    "#Διαγράμματα για το μοντέλο MLP\n",
    "plot_acc('MLP(nadam)',mlp_nadam.history['accuracy'],mlp_nadam.history['val_accuracy'])\n",
    "plot_acc('MLP(adam)',mlp_adam.history['accuracy'],mlp_adam.history['val_accuracy'])\n",
    "#Διαγράμματα για το μοντέλο LeNet\n",
    "plot_acc('LeNet(nadam)',lenet_nadam.history['accuracy'],lenet_nadam.history['val_accuracy'])\n",
    "plot_acc('LeNet(RMSprop)',lenet_rms.history['accuracy'],lenet_rms.history['val_accuracy'])\n",
    "#Διαγράμματα για το μοντέλο CNN1\n",
    "plot_acc('CNN1(nadam)',cnn1_nadam.history['accuracy'],cnn1_nadam.history['val_accuracy'])\n",
    "plot_acc('CNN1(adam)',cnn1_adam.history['accuracy'],cnn1_adam.history['val_accuracy'])\n",
    "#Διαγράμματα για το μοντέλο CNN2\n",
    "plot_acc('CNN2(nadam)',cnn2_nadam.history['accuracy'],cnn2_nadam.history['val_accuracy'])\n",
    "plot_acc('CNN2(adam)',cnn2_adam.history['accuracy'],cnn2_adam.history['val_accuracy'])\n",
    "\n",
    "#1.2.2\n",
    "### Επιλέγουμε τα ζητούμενα μοντέλα με βάση τα στοιχεία του 1.2.1. Επιδιώκουμε να έχουμε μεγάλη ακρίβεια εκπαίδευσης και, ταυτόχρονα, μικρή απόκλιση μεταξύ accuracy και val_accuracy.\n",
    "### Έτσι, παίρνουμε τις αρχιτεκτονικές: (Softmax,adam),(MLP,adam),(LeNet,nadam),(CNN1,adam) και (CNN2,adam). Οι επιλογές μας σημειώνονται με σχόλια στο κομμάτι κώδικα του ερωτήματος 1.2.1.\n",
    "### Εφεξής, χρησιμοποιούμε μόνο τις συγκεκριμένες αρχιτεκτονικές.\n",
    "### Τα ζητούμενα διαγράμματα σχεδιάστηκαν προηγουμένως, ωστόσο τα επαναφέρουμε στο τρέχον ερώτημα:\n",
    "print('Βήμα 2.2\\n')\n",
    "plot_acc('Softmax',sft_adam.history['accuracy'],sft_adam.history['val_accuracy'])\n",
    "plot_acc('MLP',mlp_adam.history['accuracy'],mlp_adam.history['val_accuracy'])\n",
    "plot_acc('LeNet',lenet_nadam.history['accuracy'],lenet_nadam.history['val_accuracy'])\n",
    "plot_acc('CNN1',cnn1_adam.history['accuracy'],cnn1_adam.history['val_accuracy'])\n",
    "plot_acc('CNN2',cnn2_adam.history['accuracy'],cnn2_adam.history['val_accuracy'])\n",
    "\n",
    "#1.2.3\n",
    "#Αριθμός κλάσεων\n",
    "### Αλλάζουμε τον αριθμό των κλάσεων (20,40,60,80) και τρέχουμε, κάθε φορά, τον κώδικα για τα επιλεγμένα μοντέλα του προηγούμενου ερωτήματος. \n",
    "### Για κάθε τέτοιο μοντέλο συγκεντρώνουμε, μέσω της συνάρτησης check_classes, τις τιμές των accuracy και val_accuracy μετά το τέλος των εποχών. \n",
    "### Έπειτα, κάνουμε τη γραφική παράσταση των παραμέτρων αυτών σε σχέση με τον αριθμό των κλάσεων. \n",
    "### Σημειώνεται πως, χάριν συντομίας, στο βήμα αυτό ο αριθμός των εποχών τίθεται ίσος με 10.\n",
    "print('Βήμα 2.3\\n')\n",
    "sft_acc_ls=[]\n",
    "mlp_acc_ls=[]\n",
    "lenet_acc_ls=[]\n",
    "cnn1_acc_ls=[]\n",
    "cnn2_acc_ls=[]\n",
    "sft_val_acc_ls=[]\n",
    "mlp_val_acc_ls=[]\n",
    "lenet_val_acc_ls=[]\n",
    "cnn1_val_acc_ls=[]\n",
    "cnn2_val_acc_ls=[]\n",
    "classes=[20,40,60,80]\n",
    "print('Επίδραση αριθμού κλάσεων\\n')\n",
    "for i in classes:\n",
    "  total=feed_data(i)\n",
    "  x_train=total[0]\n",
    "  y_train=total[1]\n",
    "  x_test=total[2]\n",
    "  y_test=total[3]\n",
    "  print(\"Number of Classes:%s\\n\" %(i)) \n",
    "  tup=check_classes(x_train,y_train,x_test,y_test,32)\n",
    "  sft_acc_ls.append(tup[0][0])\n",
    "  mlp_acc_ls.append(tup[0][1])\n",
    "  lenet_acc_ls.append(tup[0][2])\n",
    "  cnn1_acc_ls.append(tup[0][3])\n",
    "  cnn2_acc_ls.append(tup[0][4])\n",
    "  sft_val_acc_ls.append(tup[1][0])\n",
    "  mlp_val_acc_ls.append(tup[1][1])\n",
    "  lenet_val_acc_ls.append(tup[1][2])\n",
    "  cnn1_val_acc_ls.append(tup[1][3])\n",
    "  cnn2_val_acc_ls.append(tup[1][4])\n",
    "\n",
    "plot_all('Accuracy',sft_acc_ls,mlp_acc_ls,lenet_acc_ls,cnn1_acc_ls,cnn2_acc_ls,classes,0)\n",
    "plot_all('Validation Accuracy',sft_val_acc_ls,mlp_val_acc_ls,lenet_val_acc_ls,cnn1_val_acc_ls,cnn2_val_acc_ls,classes,0)\n",
    "### Παρατηρούμε πως, για μεγαλύτερο αριθμό κλάσεων, η ακρίβεια των μοντέλων μειώνεται, αφού, για διφορούμενες εικόνες, υπάρχουν, πλέον, περισσότερες επιλογές ταξινόμησης.\n",
    "\n",
    "#Αλγόριθμος Βελτιστοποίησης\n",
    "total=feed_data(20)\n",
    "x_train=total[0]\n",
    "y_train=total[1]\n",
    "x_test=total[2]\n",
    "y_test=total[3]\n",
    "opt=['SGD','RMS','Adam','Adad.','Adag.','Adamax','Nadam','Ftrl']\n",
    "print('Επίδραση optimizer\\n')\n",
    "sft_tup=check_opt('Softmax',x_train,y_train,x_test,y_test) #έλεγχος optimizers για Softmax\n",
    "mlp_tup=check_opt('MLP',x_train,y_train,x_test,y_test) #έλεγχος optimizers για MLP\n",
    "lenet_tup=check_opt('LeNet',x_train,y_train,x_test,y_test) #έλεγχος optimizers για LeNet\n",
    "cnn1_tup=check_opt('CNN1',x_train,y_train,x_test,y_test) #έλεγχος optimizers για CNN1\n",
    "cnn2_tup=check_opt('CNN2',x_train,y_train,x_test,y_test) #έλεγχος optimizers για CNN2\n",
    "plot_pairs('Softmax',sft_tup[0],sft_tup[1],opt) #για κάθε μοντέλο, κάνουμε plot, σε κοινό ραβδόγραμμα, τις ποσότητες acc και val_acc \n",
    "plot_pairs('MLP',mlp_tup[0],mlp_tup[1],opt)\n",
    "plot_pairs('LeNet',lenet_tup[0],lenet_tup[1],opt)\n",
    "plot_pairs('CNN1',cnn1_tup[0],cnn1_tup[1],opt)\n",
    "plot_pairs('CNN2',cnn2_tup[1],cnn2_tup[1],opt)\n",
    "## Τα διαγράμματα που προκύπτουν μαρτυρούν πως η επιλογή optimizer επηρεάζει σε μεγάλο βαθμό την απόδοση του μοντέλου.\n",
    "\n",
    "#Batch Size\n",
    "#Θεωρούμε ενδεικτικές τιμές batch_size=(32,64,128,256) και ελέγχουμε, όπως στο προηγούμενο βήμα, τη συμπεριφορά των αρχιτεκτονικών για κάθε περίπτωση.\n",
    "sft_acc_ls=[]\n",
    "mlp_acc_ls=[]\n",
    "lenet_acc_ls=[]\n",
    "cnn1_acc_ls=[]\n",
    "cnn2_acc_ls=[]\n",
    "sft_val_acc_ls=[]\n",
    "mlp_val_acc_ls=[]\n",
    "lenet_val_acc_ls=[]\n",
    "cnn1_val_acc_ls=[]\n",
    "cnn2_val_acc_ls=[]\n",
    "batch_size=[32,64,128,256]\n",
    "print('Επίδραση batch size\\n')\n",
    "for size in batch_size:\n",
    "  total=feed_data(20)\n",
    "  x_train=total[0]\n",
    "  y_train=total[1]\n",
    "  x_test=total[2]\n",
    "  y_test=total[3]\n",
    "  print(\"Batch Size:%s\\n\" %(size)) \n",
    "  tup=check_classes(x_train,y_train,x_test,y_test,size)\n",
    "  sft_acc_ls.append(tup[0][0])\n",
    "  mlp_acc_ls.append(tup[0][1])\n",
    "  lenet_acc_ls.append(tup[0][2])\n",
    "  cnn1_acc_ls.append(tup[0][3])\n",
    "  cnn2_acc_ls.append(tup[0][4])\n",
    "  sft_val_acc_ls.append(tup[1][0])\n",
    "  mlp_val_acc_ls.append(tup[1][1])\n",
    "  lenet_val_acc_ls.append(tup[1][2])\n",
    "  cnn1_val_acc_ls.append(tup[1][3])\n",
    "  cnn2_val_acc_ls.append(tup[1][4])\n",
    "plot_all('Accuracy',sft_acc_ls,mlp_acc_ls,lenet_acc_ls,cnn1_acc_ls,cnn2_acc_ls,batch_size,1)\n",
    "plot_all('Validation Accuracy',sft_val_acc_ls,mlp_val_acc_ls,lenet_val_acc_ls,cnn1_val_acc_ls,cnn2_val_acc_ls,batch_size,1)\n",
    "#Η ακρίβεια των μοντέλων φθίνει όσο αυξάνουμε το batch_size. Ειδικότερα, ο αριθμός των δειγμάτων ανά εποχή μειώνεται (steps_per_epoch=len(x_train)/batch_size) και, συνεπώς, το ίδιο συμβαίνει και για το learning rate.\n",
    "\n",
    "#1.3\n",
    "## Παρατηρούμε ότι, σε κάθε περίπτωση, η ακρίβεια επικύρωσης (val_accuracy) είναι μειωμένη σε σχέση με την ακρίβεια εκπαίδευσης (accuracy). Το γεγονός αυτό είναι απόρροια της υπερεκπαίδευσης των μόντελων με το υπάρχον dataset.\n",
    "\n",
    "#2.1.1\n",
    "#Early Stopping\n",
    "#Ορίζουμε τις παραμέτρους για early stopping ανάλογα με την καταγεγραμμένη ακρίβεια κάθε μοντέλου. \n",
    "#Παρακολούθουμε την πορεία των απωλειών του test set, θεωρώντας πως, για να υπάρξει βελτίωση, πρέπει να σημειωθεί πτώση τουλάχιστον κατά min_delta από την προηγούμενη εποχή.\n",
    "#Αναμένουμε κάτι τέτοιο να συμβεί εντός ενός συγκεκριμένου αριθμού περιόδων (patience), διαφορετικά σταματάμε την εκπαίδευση του μοντέλου. Η default τιμή του min_delta είναι 0.\n",
    "sft_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
    "print('Ερώτημα 2\\n')\n",
    "print('Βήμα 1.1\\n')\n",
    "print('Early Stopping\\n')\n",
    "softmax=create_sft()\n",
    "softmax.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "print(\"Model:Softmax, Optimizer:adam\") \n",
    "sft_adam=softmax.fit(x_train, y_train, epochs=20, callbacks=[sft_callback], validation_data=(x_test, y_test)) \n",
    "test_loss, test_acc = softmax.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('Softmax',sft_adam.history['accuracy'],sft_adam.history['val_accuracy'])\n",
    "\n",
    "mlp_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
    "mlp=create_mlp()\n",
    "mlp.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "print(\"Model:MLP, Optimizer:adam\")\n",
    "mlp_adam=mlp.fit(x_train, y_train, epochs=20, callbacks=[mlp_callback], validation_data=(x_test, y_test)) \n",
    "test_loss, test_acc = mlp.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('MLP',mlp_adam.history['accuracy'],mlp_adam.history['val_accuracy'])\n",
    "\n",
    "lenet_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.05, patience=1)\n",
    "lenet=create_lenet()\n",
    "lenet.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "print(\"Model:LeNet, Optimizer:nadam\")\n",
    "lenet_nadam=lenet.fit(x_train, y_train, epochs=10, callbacks=[lenet_callback], validation_data=(x_test, y_test)) \n",
    "test_loss, test_acc = lenet.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('LeNet',lenet_nadam.history['accuracy'],lenet_nadam.history['val_accuracy'])\n",
    "\n",
    "cnn1_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1)\n",
    "cnn1=create_cnn1()\n",
    "cnn1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "print(\"Model:CNN1, Optimizer:adam\")\n",
    "cnn1_adam=cnn1.fit(x_train, y_train, epochs=15, callbacks=[cnn1_callback], validation_data=(x_test, y_test)) \n",
    "test_loss, test_acc = cnn1.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('CNN1',cnn1_adam.history['accuracy'],cnn1_adam.history['val_accuracy'])\n",
    "\n",
    "cnn2_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1)\n",
    "cnn2=create_cnn2()\n",
    "cnn2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "print(\"Model:CNN2, Optimizer:adam\")\n",
    "cnn2_adam=cnn2.fit(x_train, y_train, epochs=15, callbacks=[cnn2_callback], validation_data=(x_test, y_test)) \n",
    "test_loss, test_acc = cnn2.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('CNN2',cnn2_adam.history['accuracy'],cnn2_adam.history['val_accuracy'])\n",
    "##Βλέπουμε πως η μέθοδος μπορεί να περιορίσει το φαινόμενο του overtraining.\n",
    "##Ωστόσο δεν είναι πρακτική, αφού, αφενός, διακόπτει την εκπαίδευση του δικτύου σε πρώιμα στάδια και, αφετέρου, πρέπει κάθε φορά να τροποποιείται κατάλληλα με βάση τα χαρακτηριστικά της εκάστοτε αρχιτεκτονικής.\n",
    "\n",
    "#Dropout: Μηδενισμός, κατά τρόπο τυχαίο, ενός ποσοστού των βαρών του δικτύου.\n",
    "## Επιλέγουμε την παράμετρο rate με σκοπό να μειώσουμε τη διαφορά accuracy-val_accuracy, και, παράλληλα, να διατηρήσουμε ακέραιο, όσο γίνεται, το ποσοστό της ακρίβειας εκπαίδευσης.\n",
    "softmax=create_sft()\n",
    "softmax.add(layers.Dropout(0.15))\n",
    "print('Dropout\\n')\n",
    "print(\"Model:Softmax, Optimizer:adam\") \n",
    "softmax.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy') \n",
    "sft_adam=softmax.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = softmax.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('Softmax',sft_adam.history['accuracy'],sft_adam.history['val_accuracy'])\n",
    "\n",
    "mlp=create_mlp()\n",
    "mlp.add(layers.Dropout(0.08))\n",
    "print(\"Model:MLP, Optimizer:adam\") \n",
    "mlp.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy') \n",
    "mlp_adam=mlp.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = mlp.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('MLP',mlp_adam.history['accuracy'],mlp_adam.history['val_accuracy'])\n",
    "\n",
    "lenet=create_lenet()\n",
    "lenet.add(layers.Dropout(0.2))\n",
    "print(\"Model:LeNet, Optimizer:nadam\") \n",
    "lenet.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics='accuracy') \n",
    "lenet_nadam=lenet.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = lenet.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('LeNet',lenet_nadam.history['accuracy'],lenet_nadam.history['val_accuracy'])\n",
    "\n",
    "cnn1=create_cnn1()\n",
    "cnn1.add(layers.Dropout(0.1))\n",
    "print(\"Model:CNN1, Optimizer:adam\") \n",
    "cnn1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy') \n",
    "cnn1_adam=cnn1.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = cnn1.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('CNN1',cnn1_adam.history['accuracy'],cnn1_adam.history['val_accuracy'])\n",
    "\n",
    "cnn2=create_cnn2()\n",
    "cnn2.add(layers.Dropout(0.1))\n",
    "print(\"Model:CNN2, Optimizer:adam\") \n",
    "cnn2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy') \n",
    "cnn2_adam=cnn2.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = cnn2.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('CNN2',cnn2_adam.history['accuracy'],cnn2_adam.history['val_accuracy'])\n",
    "#Η διαδικασία αυτή είναι προτιμότερη από το Early Stopping, επειδή δεν διακόπτεται η εκπαίδευση του μοντέλου.\n",
    "#Βλέπουμε πως, πλέον, το overfitting έχει περιοριστεί, αφού οι τιμές που λαμβάνουν οι μετρικές acc και val_acc είναι παρεμφερείς.\n",
    "\n",
    "#Data augmentation: Μετασχηματισμός των εικόνων του dataset.\n",
    "#Πρέπει, αρχικά, να αναπαραστήσουμε τις ετικέτες σε μορφή one_hot. Τώρα, χρησιμοποιούμε τη συνάρτηση απωλειών categorical_loss.\n",
    "y_train = keras.utils.to_categorical(y_train, 200)\n",
    "y_test = keras.utils.to_categorical(y_test, 200)\n",
    "\n",
    "#Δημιουργία generator.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#Εφαρμογή generator στο training set.\n",
    "train_data=train_datagen.flow(x_train, y_train)\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "#Δημιουργία και εκπαίδευση μοντέλων με τα νέα δεδομένα.\n",
    "softmax=create_sft()\n",
    "print('Image Augmentation\\n')\n",
    "print(\"Model:Softmax, Optimizer:adam\")\n",
    "softmax.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "sft_adam=softmax.fit_generator(train_data, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = softmax.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('Softmax',sft_adam.history['accuracy'],sft_adam.history['val_accuracy'])\n",
    "\n",
    "mlp=create_mlp()\n",
    "print(\"Model:MLP, Optimizer:adam\")\n",
    "mlp.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "mlp_adam=mlp.fit_generator(train_data, epochs=20, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = mlp.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('MLP',mlp_adam.history['accuracy'],mlp_adam.history['val_accuracy'])\n",
    "\n",
    "lenet=create_lenet()\n",
    "print(\"Model:LeNet, Optimizer:nadam\")\n",
    "lenet.compile(optimizer='nadam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "lenet_nadam=lenet.fit_generator(train_data, epochs=10, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = lenet.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('LeNet',lenet_nadam.history['accuracy'],lenet_nadam.history['val_accuracy'])\n",
    "\n",
    "cnn1=create_cnn1()\n",
    "print(\"Model:CNN1, Optimizer:adam\")\n",
    "cnn1.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "cnn1_adam=cnn1.fit_generator(train_data, epochs=15, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = cnn1.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('CNN1',cnn1_adam.history['accuracy'],cnn1_adam.history['val_accuracy'])\n",
    "\n",
    "cnn2=create_cnn2()\n",
    "print(\"Model:CNN2, Optimizer:adam\")\n",
    "cnn2.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "cnn2_adam=cnn2.fit_generator(train_data, epochs=15, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = cnn2.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('CNN2',cnn2_adam.history['accuracy'],cnn2_adam.history['val_accuracy'])\n",
    "#Το φαινόμενο του overfitting έχει εξαλειφθεί. \n",
    "#Μπορούμε να αντισταθμίσουμε την μειωμένη ακρίβεια εκπαίδευσης, εισάγοντας μεγαλύτερο αριθμό εποχών.\n",
    "\n",
    "#2.2\n",
    "## Οι προβλέψεις που αφορούν το test set παρουσιάζονται βελτιωμένες. Όμως, συγκρίνοντας τις διαφορετικές μεθόδους, παρατηρούμε πως είναι προτιμότερο να εφαρμόσουμε image augmentation.\n",
    "## Αφενός, δεν έχουμε καθόλου overfitting, και, αφετέρου, η ακρίβεια του training set μπορεί να διατηρηθεί σε επιθυμητές τιμές παρατείνοντας τον χρόνο εκπάιδευσης. \n",
    "\n",
    "#Ερώτημα 3\n",
    "## Χρησιμοποιούμε το μοντέλο MobileNetV2 από τη βιβλιοθήκη keras.applications. \n",
    "## Σκοπός μας είναι να εκπαιδεύσουμε τα τελευταία επίπεδα του δικτύου και το classification head που θα εισάγουμε. \n",
    "dimensions=(32, 32, 3)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=dimensions,include_top=False,weights='imagenet')\n",
    "#Πάγωνουμε τη συνελικτική βάση. Εξαιρείται το τελευταίο συνελικτικό τα στάδιο.\n",
    "for layer in base_model.layers:\n",
    "  if layer.name == 'Conv_1':\n",
    "    break\n",
    "  layer.trainable = False\n",
    "print('Base model summary:')\n",
    "base_model.summary()\n",
    "#Δημιουργία του τελικού μοντέλου.\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "#Προσθήκη του classification head, όπως αυτό ορίζεται στο μοντέλο CNN2.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(200, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "#Εκπαίδευση του μοντέλου με image augmentation.\n",
    "print('\\n')\n",
    "print('Ερώτημα 3\\n')\n",
    "print('Transfer learning')\n",
    "history=model.fit_generator(train_data, epochs=15, validation_data=(x_test, y_test))\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc,'\\n')\n",
    "plot_acc('Transfer Learning',history.history['accuracy'],history.history['val_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
